name: CI - Lint, Type Check, Test, Coverage, Training & Benchmarks

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install linting dependencies
      run: |
        python -m pip install --upgrade pip
        pip install ruff black isort

    - name: Lint with ruff
      run: ruff check adaptiveneuralnetwork/

    - name: Check formatting with black
      run: black --check adaptiveneuralnetwork/

    - name: Check import sorting with isort
      run: isort --check-only adaptiveneuralnetwork/

  type-check:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install type-check dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .[dev]
        pip install mypy

    - name: Type check with mypy
      run: |
        # Adjust paths if needed
        mypy adaptiveneuralnetwork/ adaptiveneuralnetwork/core/ adaptiveneuralnetwork/api/ || true
        # (Remove '|| true' if you want strict failure on any type errors)

  test:
    runs-on: ubuntu-latest
    needs: [lint, type-check]
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11", "3.12"]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/pyproject.toml', '**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Prefer editable install if using pyproject / setup.cfg
        if [ -f "pyproject.toml" ]; then
          pip install -e .[dev,nlp]
        elif [ -f "requirements.txt" ]; then
          pip install -r requirements.txt
        else
          pip install -e .
        fi
        pip install pytest pytest-cov pytest-html coverage pandas scikit-learn kagglehub matplotlib

    - name: Cache dataset
      uses: actions/cache@v3
      with:
        path: ./data
        key: hr-analytics-dataset-${{ hashFiles('**/datasets.py') }}
        restore-keys: |
          hr-analytics-dataset-

    - name: Download HR Analytics Dataset (Optional)
      run: |
        echo "=== HR ANALYTICS DATASET DOWNLOAD ==="
        mkdir -p data
        # Try to download from a public source or use synthetic data
        if [ ! -f "data/WA_Fn-UseC_-HR-Employee-Attrition.csv" ]; then
          echo "HR Analytics dataset not cached, will use synthetic data in training."
          echo "To use real dataset, add it to data/WA_Fn-UseC_-HR-Employee-Attrition.csv"
        else
          echo "HR Analytics dataset found in cache."
        fi

    - name: (Optional) Training Phase - Adaptive Neural Network Simulation
      if: matrix.python-version == '3.12'
      env:
        EPOCHS: ${{ vars.EPOCHS || '20' }}
        BATCH_SIZE: ${{ vars.BATCH_SIZE || '64' }}
      run: |
        echo "=== TRAINING PHASE (Python ${{ matrix.python-version }}) ==="
        echo "Training parameters: EPOCHS=${EPOCHS}, BATCH_SIZE=${BATCH_SIZE}"
        if [ -f "runsimulation.py" ]; then
          python runsimulation.py
          echo "Training / simulation completed."
        else
          echo "runsimulation.py not found, skipping training phase."
        fi

    - name: Run Unit Tests (No Coverage for non-3.12)
      if: matrix.python-version != '3.12'
      run: |
        echo "=== TESTS (Python ${{ matrix.python-version }}) ==="
        if [ -d "adaptiveneuralnetwork/tests" ]; then
          pytest adaptiveneuralnetwork/tests/ -v --tb=short -m "not slow"
        elif [ -d "tests" ]; then
          pytest tests/ -v --tb=short -m "not slow"
        else
          echo "No tests directory found."
        fi

    - name: Run Unit & Coverage Tests (Python 3.12)
      if: matrix.python-version == '3.12'
      run: |
        echo "=== TESTS WITH COVERAGE (Python ${{ matrix.python-version }}) ==="
        # Adjust coverage targets if needed (replace core/config with actual packages)
        TARGETS="adaptiveneuralnetwork core config"
        pytest tests/ \
          --cov=${TARGETS} \
          --cov-report=html:coverage-html \
          --cov-report=xml:coverage.xml \
          --cov-report=term-missing \
          --html=test-report.html \
          --self-contained-html \
          -v || \
        pytest adaptiveneuralnetwork/tests/ \
          --cov=${TARGETS} \
          --cov-report=html:coverage-html \
          --cov-report=xml:coverage.xml \
          --cov-report=term-missing \
          --html=test-report.html \
          --self-contained-html \
          -v

    - name: Quick Integration Test
      if: matrix.python-version == '3.12'
      run: |
        echo "=== QUICK INTEGRATION TEST ==="
        python - <<'EOF'
import sys
sys.path.append('.')
try:
    from adaptiveneuralnetwork.benchmarks.vision.mnist import quick_mnist_test
    result = quick_mnist_test(num_epochs=1, subset_size=500)
    print("Quick test completed successfully!")
    print(f"Final metrics: {result.get('final_metrics', {})}")
except Exception as e:
    print("Quick integration test failed:", e)
    raise
EOF
      timeout-minutes: 10

    - name: Bitext Training Smoke Test
      if: matrix.python-version == '3.11'
      run: |
        echo "=== BITEXT TRAINING SMOKE TEST ==="
        python -m adaptiveneuralnetwork.training.run_bitext_training \
          --mode smoke \
          --subset-size 50 \
          --output-dir test-outputs \
          --verbose
        
        # Validate output
        if [ -f "test-outputs/smoke_test_results.json" ]; then
          echo "âœ“ Bitext training smoke test completed successfully"
          python -c "
import json
with open('test-outputs/smoke_test_results.json') as f:
    result = json.load(f)
print(f'Success: {result.get(\"success\")}')
print(f'Runtime: {result.get(\"runtime_seconds\", 0):.2f}s')
if result.get('success'):
    info = result.get('dataset_info', {})
    print(f'Data: {info.get(\"train_samples\", 0)} train, {info.get(\"val_samples\", 0)} val')
          "
        else
          echo "âœ— Bitext training smoke test failed - no output file"
          exit 1
        fi
      timeout-minutes: 5

    - name: Generate Coverage Badge (Python 3.12)
      if: matrix.python-version == '3.12'
      run: |
        echo "=== COVERAGE BADGE GENERATION ==="
        if [ -f coverage.xml ]; then
          # Extract line-rate from coverage.xml
          TOTAL=$(grep -o 'line-rate="[^"]*"' coverage.xml | head -1 | cut -d'"' -f2)
          PCT=$(python - <<PY
try:
  print(round(float("${TOTAL}") * 100, 2))
except:
  print("0.0")
PY
)
          echo "Total coverage: ${PCT}%"
          COLOR="red"
          awk -v p=${PCT} 'BEGIN{if(p>=80)print "green"; else if(p>=60)print "yellow"; else print "red";}' | read COLOR
          cat > coverage-badge.json << EOF
{
  "schemaVersion": 1,
  "label": "coverage",
  "message": "${PCT}%",
  "color": "${COLOR}"
}
EOF
          printf "## Coverage Summary\n\nTotal Coverage: %s%%\n" "${PCT}" > coverage-summary.md
        else
          echo "coverage.xml not found; skipping badge."
        fi

    - name: Upload Test & Coverage Artifacts
      if: always() && matrix.python-version == '3.12'
      uses: actions/upload-artifact@v4
      with:
        name: coverage-and-tests
        path: |
          test-report.html
          coverage.xml
          coverage-html/
          coverage-summary.md
          coverage-badge.json
        retention-days: 30

    - name: Upload Test Results (Non-Coverage Runs)
      if: always() && matrix.python-version != '3.12'
      uses: actions/upload-artifact@v4
      with:
        name: test-results-python${{ matrix.python-version }}
        path: |
          test-report.html
        if-no-files-found: ignore
        retention-days: 14

    - name: Upload Training Artifacts
      if: matrix.python-version == '3.12'
      uses: actions/upload-artifact@v4
      with:
        name: training-artifacts-python${{ matrix.python-version }}
        path: |
          outputs/
          *.json
          *.db
          *.png
        if-no-files-found: warn
        retention-days: 30

    - name: Comment Coverage on PR
      if: matrix.python-version == '3.12' && github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('coverage-summary.md')) {
            const coverage = fs.readFileSync('coverage-summary.md', 'utf8');
            const body = `## ðŸ“Š Coverage Report\n\n${coverage}`;
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body
            });
          } else {
            console.log("No coverage-summary.md found; skipping PR comment.");
          }

  benchmark:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: [test]
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install runtime dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Cache dataset
      uses: actions/cache@v3
      with:
        path: ./data
        key: hr-analytics-dataset-${{ hashFiles('**/datasets.py') }}
        restore-keys: |
          hr-analytics-dataset-

    - name: Run benchmark
      run: |
        if [ -f "scripts/run_benchmark.py" ]; then
          python scripts/run_benchmark.py --epochs 2 --subset-size 2000 --quick-test
        else
          echo "scripts/run_benchmark.py not found; skipping benchmark."
        fi
      timeout-minutes: 20

    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: |
          *.json
          profiling_results/
          checkpoints/
        if-no-files-found: warn
        retention-days: 30